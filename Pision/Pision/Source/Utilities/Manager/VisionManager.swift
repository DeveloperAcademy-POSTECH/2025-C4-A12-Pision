//
//  VisionManager.swift
//  PisionTest2
//
//  Created by ì—¬ì„±ì¼ on 7/13/25.
//

import Foundation
import Vision

// MARK: - VisionManager
final class VisionManager: ObservableObject {
  // Published Var
  @Published private(set) var ears: [Float] = []
  @Published private(set) var yaws: [Float] = []
  @Published private(set) var latestYaw: Float = 10.0
  @Published private(set) var shoulderPoints: (left: CGPoint, right: CGPoint)? = nil
  @Published private(set) var faceRectangle: [CGRect] = []
  @Published private(set) var mlPredictions: [String] = []
  @Published private(set) var blinkCount: Int = 0
  @Published private(set) var isFistHeld: Bool = false
  
  // 30ì´ˆ ë‹¨ìœ„ ì¸¡ì •ì„ ìœ„í•œ ìƒˆë¡œìš´ ë°°ì—´ë“¤
  @Published private(set) var currentSegmentEars: [Float] = []
  @Published private(set) var currentSegmentYaws: [Float] = []
  @Published private(set) var currentSegmentMLPredictions: [String] = []
  @Published private(set) var currentSegmentBlinkCount: Int = 0
  
  // 30ì´ˆ ë‹¨ìœ„ ê²°ê³¼ë¥¼ ì €ì¥í•˜ëŠ” ë°°ì—´ë“¤
  @Published private(set) var coreScoreSegments: [CoreScoreModel] = []
  @Published private(set) var auxScoreSegments: [AuxScoreModel] = []
  
  var onSnoozeDetected: ((Bool) -> Void)?
  var onFistDetected: (() -> Void)?
  var onSegmentCompleted: ((CoreScoreModel, AuxScoreModel) -> Void)?
  
  // General var
  private let sequenceHandler = VNSequenceRequestHandler()
  private let faceRequest = VNDetectFaceLandmarksRequest()
  private let poseRequest = VNDetectHumanBodyPoseRequest()
  private let handRequest = VNDetectHumanHandPoseRequest()
  
  private var snoozeCounter = 0
  private let snoozeThresholdFrames = 30 // ì•½ 2ì´ˆ (15fps ê¸°ì¤€)
  private var isSnoozeAlreadyDetected = false
  
  // 30ì´ˆ íƒ€ì´ë¨¸ ê´€ë ¨
  private var segmentTimer: Timer?
  private var segmentStartTime: Date?
  
  // Manager
  private let mlManager = MLManager()!
  private let scoreManager = ScoreManager()
  
  private var isBlink: Bool = false
  private var firstWorkItem: DispatchWorkItem?
}

// MARK: - General Func
extension VisionManager {
  /// ëª¨ë“  ë°ì´í„°ë¥¼ ì´ˆê¸°í™” í•©ë‹ˆë‹¤.
  /// ìƒˆë¡œìš´ ì„¸ì…˜ì´ë‚˜, ì¸¡ì •ì„ ì‹œì‘í•˜ê¸° ì „ì— ì´ì „ ë°ì´í„°ë¥¼ ì´ˆê¸°í™”í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
  func reset() {
    ears.removeAll()
    yaws.removeAll()
    mlPredictions.removeAll()
    blinkCount = 0
    
    // 30ì´ˆ ë‹¨ìœ„ ë°ì´í„° ì´ˆê¸°í™”
    currentSegmentEars.removeAll()
    currentSegmentYaws.removeAll()
    currentSegmentMLPredictions.removeAll()
    currentSegmentBlinkCount = 0
    
    // ê²°ê³¼ ë°°ì—´ ì´ˆê¸°í™”
    coreScoreSegments.removeAll()
    auxScoreSegments.removeAll()
    
    // íƒ€ì´ë¨¸ ì •ë¦¬
    stopSegmentTimer()
  }
  
  /// 30ì´ˆ ë‹¨ìœ„ ì¸¡ì •ì„ ì‹œì‘í•©ë‹ˆë‹¤.
  func startSegmentMeasurement() {
    stopSegmentTimer()
    segmentStartTime = Date()
    
    segmentTimer = Timer.scheduledTimer(withTimeInterval: 30.0, repeats: true) { [weak self] _ in
      self?.completeCurrentSegment()
    }
  }
  
  /// 30ì´ˆ ë‹¨ìœ„ ì¸¡ì •ì„ ì¤‘ì§€í•©ë‹ˆë‹¤.
  func stopSegmentTimer() {
    segmentTimer?.invalidate()
    segmentTimer = nil
  }
  
  /// í˜„ì¬ 30ì´ˆ êµ¬ê°„ì„ ì™„ë£Œí•˜ê³  ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
  private func completeCurrentSegment() {
    // 30ì´ˆ êµ¬ê°„ì´ ì™„ë£Œë˜ì§€ ì•Šì€ ê²½ìš° ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ
    guard !currentSegmentEars.isEmpty else {
      print("âš ï¸ ë¹ˆ êµ¬ê°„ì´ë¯€ë¡œ ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
      return
    }
    
    // í˜„ì¬ êµ¬ê°„ì˜ ë°ì´í„°ë¡œ ì ìˆ˜ ê³„ì‚°
    let coreScore = scoreManager.calculateCore(
      from: currentSegmentEars,
      yaws: currentSegmentYaws,
      blinkCount: currentSegmentBlinkCount
    )
    
    let auxScore = scoreManager.calculateAux(
      from: currentSegmentEars,
      yaws: currentSegmentYaws,
      ml: currentSegmentMLPredictions,
      blinkCount: currentSegmentBlinkCount
    )
    
    // ê²°ê³¼ ì €ì¥
    coreScoreSegments.append(coreScore)
    auxScoreSegments.append(auxScore)
    
    // ì „ì²´ ë°ì´í„°ì—ë„ ì¶”ê°€
    ears.append(contentsOf: currentSegmentEars)
    yaws.append(contentsOf: currentSegmentYaws)
    mlPredictions.append(contentsOf: currentSegmentMLPredictions)
    blinkCount += currentSegmentBlinkCount
    
    print("âœ… 30ì´ˆ êµ¬ê°„ #\(coreScoreSegments.count) ì™„ë£Œ - Core: \(String(format: "%.1f", coreScore.coreScore)), Aux: \(String(format: "%.1f", auxScore.auxScore))")
    
    // ì½œë°± í˜¸ì¶œ
    onSegmentCompleted?(coreScore, auxScore)
    
    // í˜„ì¬ êµ¬ê°„ ë°ì´í„° ì´ˆê¸°í™”
    currentSegmentEars.removeAll()
    currentSegmentYaws.removeAll()
    currentSegmentMLPredictions.removeAll()
    currentSegmentBlinkCount = 0
  }
  
  /// ì¸¡ì • ì™„ë£Œ ì‹œ ë§ˆì§€ë§‰ êµ¬ê°„ ì²˜ë¦¬
  func finalizeMeasurement() {
    // 30ì´ˆ ë¯¸ë§Œì˜ ë§ˆì§€ë§‰ êµ¬ê°„ì€ ì €ì¥í•˜ì§€ ì•Šê³  ì œê±°
    if !currentSegmentEars.isEmpty {
      print("âš ï¸ ë§ˆì§€ë§‰ \(currentSegmentEars.count)ê°œ í”„ë ˆì„ì˜ ë¯¸ì™„ë£Œ êµ¬ê°„ì€ ì €ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
      
      // í˜„ì¬ êµ¬ê°„ ë°ì´í„° ì´ˆê¸°í™” (ì €ì¥í•˜ì§€ ì•ŠìŒ)
      currentSegmentEars.removeAll()
      currentSegmentYaws.removeAll()
      currentSegmentMLPredictions.removeAll()
      currentSegmentBlinkCount = 0
    }
    
    stopSegmentTimer()
    
    print("ğŸ“Š ìµœì¢… ì €ì¥ëœ 30ì´ˆ êµ¬ê°„ ìˆ˜: \(coreScoreSegments.count)ê°œ")
  }
  
  /// ì–¼êµ´ì˜ ëœë“œë§ˆí¬ ì •ë³´ë¥¼ ì²˜ë¦¬í•˜ì—¬ ê³ ê°œ íšŒì „ ê°ë„(YAW), ëˆˆ ë¹„ìœ¨(EAR), ëˆˆ ê¹œë¹¡ì„ ì—¬ë¶€ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
  /// Vision í”„ë ˆì„ì›Œí¬ë¥¼ ì´ìš©í•´ ì–¼êµ´ì„ ë¶„ì„í•˜ê³ , ë¶„ì„ëœ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‚´ë¶€ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
  /// - Parameter pixelBuffer: ë¶„ì„í•  ì˜ìƒ í”„ë ˆì„ì˜ í”½ì…€ ë²„í¼ì…ë‹ˆë‹¤.
  func processMeasureFaceLandMark(pixelBuffer: CVPixelBuffer) {
    do {
      try sequenceHandler.perform([faceRequest], on: pixelBuffer)
      guard let results = faceRequest.results, !results.isEmpty else {
        DispatchQueue.main.async {
          self.latestYaw = 10.0
        }
        return
      }
      
      for face in results {
        if let yaw = face.yaw?.floatValue {
          let absYaw = abs(yaw)
          currentSegmentYaws.append(absYaw)
        }
        
        if let landmarks = face.landmarks,
           let leftEye = landmarks.leftEye,
           let rightEye = landmarks.rightEye {
          let leftEAR = calculateEAR(leftEye)
          let rightEAR = calculateEAR(rightEye)
          let avgEAR = (leftEAR + rightEAR) / 2.0
          currentSegmentEars.append(avgEAR)
          countBlink(leftEAR: CGFloat(leftEAR), rightEAR: CGFloat(rightEAR))
        }
      }
    } catch {
      print("Face Landmark ì²˜ë¦¬ ì‹¤íŒ¨")
    }
  }
  
  func processGuidingFaceLandMark(pixelBuffer: CVPixelBuffer) {
    do {
      try sequenceHandler.perform([faceRequest], on: pixelBuffer)
      guard let results = faceRequest.results, !results.isEmpty else {
        return
      }
      
      for face in results {
        if let yaw = face.yaw?.floatValue {
          let absYaw = abs(yaw)
          DispatchQueue.main.async {
            self.latestYaw = absYaw
          }
        }
      }
    } catch {
      print("Face Landmark ì²˜ë¦¬ ì‹¤íŒ¨")
    }
  }
  
  func processMeasureBodyPose(pixelBuffer: CVPixelBuffer) {
    do {
      try sequenceHandler.perform([poseRequest], on: pixelBuffer)
      guard let first = poseRequest.results?.first else { return }

      let label = mlManager.bodyPosePredict(from: first)
      
      DispatchQueue.main.async {
        self.currentSegmentMLPredictions.append(label)
        
        let lastEAR = self.currentSegmentEars.last ?? 1.0
        let isSnoozePose = (label == "Snooze")
        let isEyesClosed = lastEAR < 0.1
        
        // snooze ì¡°ê±´ ì¶©ì¡± ì¤‘ì¼ ë•Œ ëˆ„ì 
        if isSnoozePose && isEyesClosed {
          self.snoozeCounter += 1
          
          if self.snoozeCounter >= self.snoozeThresholdFrames && !self.isSnoozeAlreadyDetected {
            self.isSnoozeAlreadyDetected = true
            self.onSnoozeDetected?(true)
          }
        } else {
          // ì¡°ê±´ ì¶©ì¡± ì•ˆ í•˜ë©´ ì´ˆê¸°í™”
          self.snoozeCounter = 0
          self.isSnoozeAlreadyDetected = false
          self.onSnoozeDetected?(false)
        }
      }
    } catch {
      print("Body Pose ì²˜ë¦¬ ì‹¤íŒ¨")
    }
  }
  
  func processGuidingBodyPose(pixelBuffer: CVPixelBuffer) {
    do {
      try sequenceHandler.perform([poseRequest], on: pixelBuffer)
      guard let first = poseRequest.results?.first else { return }
      
      // ì–´ê¹¨ ìœ„ì¹˜ ì²´í¬ (ê¸°ì¡´)
      guard let left = try? first.recognizedPoint(.leftShoulder),
            let right = try? first.recognizedPoint(.rightShoulder),
            left.confidence > 0.2, right.confidence > 0.2 else {
        DispatchQueue.main.async {
          self.shoulderPoints = nil
        }
        return
      }
      
      let points = (left: CGPoint(x: left.x, y: left.y),
                    right: CGPoint(x: right.x, y: right.y))
      
      DispatchQueue.main.async {
        self.shoulderPoints = points
      }
    } catch {
      print("Body Pose ì²˜ë¦¬ ì‹¤íŒ¨")
    }
  }
  
  func processHandPose(pixelBuffer: CVPixelBuffer) {
    do {
      try sequenceHandler.perform([handRequest], on: pixelBuffer)
      guard let first = handRequest.results?.first else { return }
      
      let label = mlManager.handPosePredict2(from: first).label
      let confidence = mlManager.handPosePredict2(from: first).confidence
      DispatchQueue.main.async {
        self.startFistTimer(label: label, confidence: confidence)
      }
    } catch {
      print("Hand Pose ì²˜ë¦¬ ì‹¤íŒ¨")
    }
  }
}

// MARK: - Private Func
extension VisionManager {
  /// ëˆˆì˜ EAR(Eye Aspect Ratio)ì„ ê³„ì‚°í•˜ì—¬ ëˆˆì´ ì–¼ë§ˆë‚˜ ê°ê²¨ ìˆëŠ”ì§€ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤.
  /// EAR ê°’ì´ ì‘ì„ìˆ˜ë¡ ëˆˆì´ ê°ê¸´ ìƒíƒœì— ê°€ê¹ìŠµë‹ˆë‹¤.
  /// - Parameter eye: Visionì—ì„œ ì¶”ì¶œëœ ëˆˆì˜ ëœë“œë§ˆí¬ í¬ì¸íŠ¸ì…ë‹ˆë‹¤.
  /// - Returns: ê³„ì‚°ëœ EAR ê°’ì…ë‹ˆë‹¤. í¬ì¸íŠ¸ê°€ ë¶€ì¡±í•  ê²½ìš° ê¸°ë³¸ê°’ 0.25ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
  private func calculateEAR(_ eye: VNFaceLandmarkRegion2D) -> Float {
    let pts = eye.normalizedPoints
    guard pts.count >= 6 else { return 0.25 }
    let v1 = pts[1].eyeDistance(to: pts[5])
    let v2 = pts[2].eyeDistance(to: pts[4])
    let h = pts[0].eyeDistance(to: pts[3])
    return Float((v1 + v2) / (2 * h))
  }
  
  /// ì–‘ìª½ ëˆˆì˜ EAR ê°’ì„ ê¸°ë°˜ìœ¼ë¡œ ëˆˆ ê¹œë¹¡ì„ ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ê³  ê¹œë¹¡ì„ íšŸìˆ˜ë¥¼ ì¦ê°€ì‹œí‚µë‹ˆë‹¤.
  /// EAR ê°’ì´ ì¼ì • ì„ê³„ê°’(threshold)ë³´ë‹¤ ì‘ì„ ê²½ìš° ëˆˆì„ ê°ì€ ê²ƒìœ¼ë¡œ íŒë‹¨í•©ë‹ˆë‹¤.
  /// - Parameters:
  ///   - leftEAR: ì™¼ìª½ ëˆˆì˜ EAR ê°’
  ///   - rightEAR: ì˜¤ë¥¸ìª½ ëˆˆì˜ EAR ê°’
  ///   - threshold: ëˆˆ ê°ê¹€ì„ íŒë‹¨í•  ê¸°ì¤€ EAR ì„ê³„ê°’ (ê¸°ë³¸ê°’: 0.1)
  private func countBlink(leftEAR: CGFloat, rightEAR: CGFloat, threshold: CGFloat = 0.1) {
    let leftClosed = leftEAR < threshold
    let rightClosed = rightEAR < threshold
    if leftClosed && rightClosed {
      if !isBlink { isBlink = true }
    } else {
      if isBlink {
        currentSegmentBlinkCount += 1
        isBlink = false
      }
    }
  }
  
  private func startFistTimer(label: String, confidence: Double) {
      if label == "Fist" && confidence > 0.99 {
        if self.firstWorkItem == nil {
          let work = DispatchWorkItem { [weak self] in
            self?.onFistDetected?()
          }
          self.firstWorkItem = work
          DispatchQueue.main.asyncAfter(deadline: .now() + 0.5, execute: work)
        }
      } else {
        self.resetFistTimer()
      }
    }
  
  private func resetFistTimer() {
    firstWorkItem?.cancel()
    firstWorkItem = nil
    isFistHeld = false
  }
}
